{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fa70af",
   "metadata": {},
   "source": [
    "### Theory About Reproducibility\n",
    "Reproducing or rather producing the quantized model is the deadliest pain the ass I have felt in a while. It was bad.\n",
    "\n",
    "Keeping the technicalities about SELECT_OPS and Flex Delegate etc aside, just confirm your setup as follow. I have already talked about using virtual environment as kernel in diskloader.ipynb\n",
    "\n",
    "Final setup\n",
    "- OS: Ubuntu Server  \n",
    "- Python: 3.12  \n",
    "- TensorFlow: 2.18.0 (regular, CPU-only)  \n",
    "  - Do NOT use `tensorflow[and-cuda]` (conversion fails).  \n",
    "  - Regular `tensorflow==2.18.0` works fine with Python 3.12.\n",
    "    ```bash\n",
    "    pip uninstall -y tensorflow[and-cuda]\n",
    "    pip install tensorflow==2.18.*\n",
    "    ````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec797e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming virtual environment .tens with python 3.12 is being used\n",
    "# %pip install tensorflow==2.18.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3aac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('best_model_345_classes_30000_examples.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81e27e",
   "metadata": {},
   "source": [
    "#### Converting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Enable Flex ops (Select TensorFlow Ops)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # ‚Üê this is the fix\n",
    "]\n",
    "\n",
    "# Optional optimizations\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('best_model_345_classes_30000_examples.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d05c7",
   "metadata": {},
   "source": [
    "#### Loading and Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"best_model_345_classes_30000_examples.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details, output_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
