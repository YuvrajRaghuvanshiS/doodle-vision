{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2709d93f",
   "metadata": {},
   "source": [
    "### Prerequisites (uncomment to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f38335",
   "metadata": {},
   "source": [
    "#### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb745e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow[and-cuda] numpy tqdm matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ccecc",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Download QuickDraw dataset\n",
    "# %python download_data.py\n",
    "\n",
    "# # Step 2: Combine stroke data across different partitions (train, val, test).\n",
    "# # The original data (e.g., airplanes.npz) is split into these partitions, \n",
    "# # which reduces the number of data points. We merge all partitions for a complete dataset.\n",
    "# %python combine_strokes.py\n",
    "\n",
    "# # Step 3: Convert each `.npy` and `.npz` file into individual sample files.\n",
    "# # For example, `airplanes.npy` contains (N, 784), where N is the number of samples \n",
    "# # and each sample is a flattened 28x28 image (784 features). We split this into\n",
    "# # individual `.npy` files like `airplanes/000001.npy`, `airplanes/000002.npy`, etc.\n",
    "# # This allows us to load specific slices of data (e.g., airplanes[3012:33012]) \n",
    "# # without having to load the entire file, reducing memory usage and avoiding memory eviction issues.\n",
    "# %python convert_to_individual_npys.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767a42d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import (\n",
    "    BackupAndRestore,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    BatchNormalization,\n",
    "    Bidirectional,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    GlobalAveragePooling2D,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c4aea",
   "metadata": {},
   "source": [
    "### GPU Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f91654",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c56e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "DATA_DIR_IMAGES = \"dataset/images\"\n",
    "DATA_DIR_STROKES = \"dataset/combined_strokes\"\n",
    "LABELS_JSON    = \"dataset/label_map.json\"\n",
    "PROCESSED_DATA_DIR = \"dataset/processed\"\n",
    "\n",
    "# Data props\n",
    "NUM_CLASSES = 345\n",
    "\n",
    "# Data props (image)\n",
    "IMG_HEIGHT     = 28\n",
    "IMG_WIDTH      = 28\n",
    "IMG_CHANNELS   = 1\n",
    "\n",
    "# Data props (stroke)\n",
    "MAX_STROKES_LEN = 130\n",
    "STROKES_FEATURES = 3\n",
    "\n",
    "# Training\n",
    "SAMPLES_PER_CLASS = 30_000\n",
    "SPLIT_RATIOS = (0.8, 0.1, 0.1) # train, val, test\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 20\n",
    "\n",
    "# General Config\n",
    "USE_INDIVIDUAL = True # Whether using the downloaded npy files or preprocessed individual example npy files\n",
    "\n",
    "# In-memory loading threshold (for 10_000, used 11% of 128GB memory)\n",
    "IN_MEMORY_THRESHOLD = 30_000  # Load everything to RAM early-on if SAMPLES_PER_CLASS <= this, otherwise load inside the generator\n",
    "USE_IN_MEMORY = USE_INDIVIDUAL and (SAMPLES_PER_CLASS <= IN_MEMORY_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592eab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_JSON, 'r') as f:\n",
    "    LABEL_MAP = json.load(f)\n",
    "    \n",
    "REV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef4864",
   "metadata": {},
   "source": [
    "### Data Preprocessing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(flat_img):\n",
    "    \"\"\"\n",
    "    Input shape: (784,)\n",
    "    Output shape: (28, 28, 1), normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    img = flat_img.reshape(28, 28).astype(np.float32) / 255.0\n",
    "    return np.expand_dims(img, axis=-1)  # shape: (28, 28, 1)\n",
    "\n",
    "def preprocess_strokes(strokes, max_len=MAX_STROKES_LEN):\n",
    "    \"\"\"\n",
    "    Improved stroke preprocessing with consistent normalization\n",
    "    Centers to (0,0) and scales to [-100, 100] range\n",
    "    \"\"\"\n",
    "    strokes = strokes.astype(np.float32)\n",
    "\n",
    "    # Convert to absolute coordinates\n",
    "    strokes[:, 0] = np.cumsum(strokes[:, 0])\n",
    "    strokes[:, 1] = np.cumsum(strokes[:, 1])\n",
    "\n",
    "    # Center to (0, 0)\n",
    "    strokes[:, 0] -= strokes[:, 0].mean()\n",
    "    strokes[:, 1] -= strokes[:, 1].mean()\n",
    "\n",
    "    # Scale to [-100, 100] range\n",
    "    if len(strokes) > 0:\n",
    "        # Find the maximum absolute coordinate value\n",
    "        max_coord = max(\n",
    "            np.abs(strokes[:, 0]).max() if len(strokes) > 0 else 1,\n",
    "            np.abs(strokes[:, 1]).max() if len(strokes) > 0 else 1,\n",
    "        )\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if max_coord > 0:\n",
    "            # Scale to [-100, 100] range\n",
    "            scale_factor = 100.0 / max_coord\n",
    "            strokes[:, 0] *= scale_factor\n",
    "            strokes[:, 1] *= scale_factor\n",
    "\n",
    "    # Truncate or pad as before\n",
    "    if len(strokes) > max_len:\n",
    "        return strokes[:max_len]\n",
    "\n",
    "    pad = np.zeros((max_len - len(strokes), STROKES_FEATURES), dtype=np.float32)\n",
    "\n",
    "    return np.vstack([strokes, pad])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3fc72",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c004ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_model(num_classes):\n",
    "    inp_str = Input(shape=(MAX_STROKES_LEN, STROKES_FEATURES), name=\"stroke_input\")\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(inp_str)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    inp_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name=\"image_input\")\n",
    "    y = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inp_img)\n",
    "    y = MaxPooling2D()(y)\n",
    "    y = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "    y = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "    y = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "    y = GlobalAveragePooling2D()(y)\n",
    "    y = Dense(128, activation=\"relu\")(y)\n",
    "\n",
    "    merged = Concatenate()([x, y])\n",
    "    merged = Dropout(0.5)(merged)\n",
    "    merged = Dense(256, activation=\"relu\")(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    out = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(merged)\n",
    "\n",
    "    return Model(inputs=[inp_str, inp_img], outputs=out, name=\"hybrid_model\")\n",
    "\n",
    "model = build_hybrid_model(num_classes=NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8966c",
   "metadata": {},
   "source": [
    "### Disk Data Loader for Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8231a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When USE_IN_MEMORY: list of numpy objects\n",
    "# When USE_INDIVIDUAL: list of file paths\n",
    "# Otherwise: list of (cls_id, example_id)\n",
    "images = []\n",
    "strokes = []\n",
    "\n",
    "# Always list of integers\n",
    "labels = []\n",
    "\n",
    "if USE_INDIVIDUAL:\n",
    "    for cls, label in tqdm(LABEL_MAP.items(), desc=\"Building dataset\"):\n",
    "        image_files = sorted(\n",
    "            glob(os.path.join(PROCESSED_DATA_DIR, \"images\", cls, \"*.npy\"))\n",
    "        )\n",
    "        stroke_files = sorted(\n",
    "            glob(os.path.join(PROCESSED_DATA_DIR, \"strokes\", cls, \"*.npy\"))\n",
    "        )\n",
    "\n",
    "        N = min(len(image_files), len(stroke_files), SAMPLES_PER_CLASS)\n",
    "\n",
    "        for i in range(N):\n",
    "            image_path = image_files[i]\n",
    "            stroke_path = stroke_files[i]\n",
    "\n",
    "            if USE_IN_MEMORY:\n",
    "                images.append(np.load(image_path))\n",
    "                strokes.append(np.load(stroke_path))\n",
    "            else:\n",
    "                images.append(image_path)\n",
    "                strokes.append(stroke_path)\n",
    "            labels.append(label)\n",
    "\n",
    "    if USE_IN_MEMORY:\n",
    "        print(f\"[In-Memory Mode] Loaded {len(labels):,} samples.\")\n",
    "    else:\n",
    "        print(f\"[Individual Stream Mode] Loaded {len(labels):,} samples.\")\n",
    "\n",
    "else:\n",
    "    for cls, label in tqdm(LABEL_MAP.items(), desc=\"Building dataset\"):\n",
    "        image_path = os.path.join(DATA_DIR_IMAGES, f\"{cls}.npy\")\n",
    "        stroke_path = os.path.join(DATA_DIR_STROKES, f\"{cls}.npz\")\n",
    "\n",
    "        img_arr = np.load(image_path, allow_pickle=True, encoding=\"latin1\", mmap_mode=\"r\")\n",
    "        str_arr = np.load(stroke_path, allow_pickle=True, encoding=\"latin1\")[\"strokes\"]\n",
    "\n",
    "        N = min(img_arr.shape[0], len(str_arr), SAMPLES_PER_CLASS)\n",
    "\n",
    "        for i in range(N):\n",
    "            images.append((label, i))\n",
    "            strokes.append((label, i))\n",
    "            labels.append(label)\n",
    "\n",
    "    print(f\"[Original Mode] Loaded {len(labels):,} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_strokes(images, strokes, labels, n=100):\n",
    "    # Pick n random indices\n",
    "    idxs = random.sample(range(len(labels)), n)\n",
    "\n",
    "    plt.figure(figsize=(10, n * 1.5))  # Large enough for many rows\n",
    "    for i, idx in enumerate(idxs):\n",
    "        # Load image\n",
    "        if isinstance(images[idx], str):  # Path\n",
    "            img = np.load(images[idx])\n",
    "        elif isinstance(images[idx], tuple):  # (label, i) for Original Mode\n",
    "            label_id, ex_id = images[idx]\n",
    "            cls = list(LABEL_MAP.keys())[label_id]\n",
    "            img = np.load(os.path.join(DATA_DIR_IMAGES, f\"{cls}.npy\"), \n",
    "                          mmap_mode=\"r\")[ex_id]\n",
    "        else:  # Already in memory\n",
    "            img = images[idx]\n",
    "\n",
    "        img = img.reshape(28, 28)\n",
    "\n",
    "        # Load stroke\n",
    "        if isinstance(strokes[idx], str):  # Path\n",
    "            strk = np.load(strokes[idx])\n",
    "        elif isinstance(strokes[idx], tuple):  # (label, i)\n",
    "            label_id, ex_id = strokes[idx]\n",
    "            cls = list(LABEL_MAP.keys())[label_id]\n",
    "            str_arr = np.load(os.path.join(DATA_DIR_STROKES, f\"{cls}.npz\"),\n",
    "                              allow_pickle=True)[\"strokes\"]\n",
    "            strk = str_arr[ex_id]\n",
    "        else:  # Already in memory\n",
    "            strk = strokes[idx]\n",
    "\n",
    "        # Plot\n",
    "        plt.subplot(n, 2, 2*i + 1)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Label: {labels[idx]}\")\n",
    "\n",
    "        plt.subplot(n, 2, 2*i + 2)\n",
    "        plt.plot(strk[:, 0], -strk[:, 1], marker='o', markersize=1)  # Flip y-axis for natural orientation\n",
    "        plt.axis(\"equal\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{n}_random_samples.png')\n",
    "\n",
    "\n",
    "plot_images_and_strokes(images, strokes, labels, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8326d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(images, strokes, labels):\n",
    "    # no preprocess stroke or preprocess image because that is already taken care of while \n",
    "    # using convert_to_individual_npys.py\n",
    "    if USE_IN_MEMORY:\n",
    "        for image, stroke, label in zip(images, strokes, labels):\n",
    "            yield (\n",
    "                image,\n",
    "                stroke,\n",
    "                tf.one_hot(label, depth=NUM_CLASSES),\n",
    "            )\n",
    "    elif USE_INDIVIDUAL:\n",
    "        for img_path, str_path, label in zip(images, strokes, labels):\n",
    "            yield (\n",
    "                np.load(img_path),\n",
    "                np.load(str_path),\n",
    "                tf.one_hot(label, depth=NUM_CLASSES),\n",
    "            )\n",
    "    else:\n",
    "        for (img_id, i), (str_id, j), label in zip(images, strokes, labels):\n",
    "            img_path = os.path.join(DATA_DIR_IMAGES, REV_LABEL_MAP[img_id], \".npy\")\n",
    "            str_path = os.path.join(DATA_DIR_STROKES, REV_LABEL_MAP[str_id], \".npz\")\n",
    "            \n",
    "            img = np.load(img_path, allow_pickle=True, encoding=\"latin1\", mmap_mode=\"r\")[i]\n",
    "            strokes = np.load(str_path, allow_pickle=True, encoding=\"latin1\")[\"strokes\"][j]\n",
    "            yield (\n",
    "                preprocess_image(img),\n",
    "                preprocess_strokes(strokes),\n",
    "                tf.one_hot(label, depth=NUM_CLASSES),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35abf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sample(img, stroke, label):\n",
    "    return {\"stroke_input\": stroke, \"image_input\": img}, label\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(28, 28, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(130, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(NUM_CLASSES,), dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433acb88",
   "metadata": {},
   "source": [
    "### Train, Val, and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c977bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle once and split\n",
    "total = len(labels)\n",
    "indices = np.arange(total)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_end = int(SPLIT_RATIOS[0] * total)\n",
    "val_end = train_end + int(SPLIT_RATIOS[1] * total)\n",
    "\n",
    "train_idx = indices[:train_end]\n",
    "val_idx = indices[train_end:val_end]\n",
    "test_idx = indices[val_end:]\n",
    "\n",
    "# Train\n",
    "train_images =  [images[i] for i in train_idx]\n",
    "train_strokes = [strokes[i] for i in train_idx]\n",
    "train_labels =  [labels[i] for i in train_idx]\n",
    "\n",
    "# Val\n",
    "val_images =  [images[i] for i in val_idx]\n",
    "val_strokes = [strokes[i] for i in val_idx]\n",
    "val_labels =  [labels[i] for i in val_idx]\n",
    "\n",
    "# Test\n",
    "test_images =  [images[i] for i in test_idx]\n",
    "test_strokes = [strokes[i] for i in test_idx]\n",
    "test_labels =  [labels[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(images, strokes, labels, is_shuffle=False):\n",
    "    def gen():\n",
    "        return data_generator(images, strokes, labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "\n",
    "    if is_shuffle:\n",
    "        ds = ds.shuffle(BATCH_SIZE * 10)\n",
    "\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.map(format_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_dataset(train_images, train_strokes, train_labels, is_shuffle=True)\n",
    "val_ds  = build_dataset(val_images, val_strokes, val_labels).take(math.ceil(len(val_labels) / BATCH_SIZE))\n",
    "test_ds = build_dataset(test_images, test_strokes, test_labels).take(math.ceil(len(test_labels) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072608cf",
   "metadata": {},
   "source": [
    "### Model Training and graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryCleanupCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "\n",
    "model_name = f\"best_model_{NUM_CLASSES}_classes_{SAMPLES_PER_CLASS}_examples\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(f\"{model_name}.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "    MemoryCleanupCallback(),\n",
    "    BackupAndRestore(backup_dir=\"./training_backup\"),\n",
    "    TensorBoard(\n",
    "        log_dir=f\"./logs/fit/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "        histogram_freq=1,  # logs weights histograms every epoch\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=math.ceil(len(train_labels) / BATCH_SIZE),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "with open(f\"{model_name}_training_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f85beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630380b",
   "metadata": {},
   "source": [
    "### Model Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = tf.keras.models.load_model(model_name)\n",
    "loss, acc = eval_model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f} | Test Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
